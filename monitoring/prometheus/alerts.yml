# CRITICAL: Alert Rules for GangRun Printing Production Monitoring

groups:
  # ========================================
  # BUSINESS ALERTS
  # ========================================
  - name: business_alerts
    interval: 30s
    rules:
      - alert: NoOrdersIn2Hours
        expr: increase(gangrun_orders_total[2h]) == 0
        for: 5m
        labels:
          severity: warning
          team: business
        annotations:
          summary: "No orders received in 2 hours"
          description: "The system has not received any orders in the last 2 hours. This could indicate a business issue or technical problem."

      - alert: HighOrderFailureRate
        expr: rate(gangrun_orders_total{status="failed"}[1h]) / rate(gangrun_orders_total[1h]) > 0.05
        for: 5m
        labels:
          severity: critical
          team: business
        annotations:
          summary: "High order failure rate detected"
          description: "Order failure rate is {{ $value | humanizePercentage }}. More than 5% of orders are failing."

      - alert: LowRevenueAlert
        expr: increase(gangrun_revenue_total_cents[1h]) < 10000
        for: 1h
        labels:
          severity: warning
          team: business
        annotations:
          summary: "Low revenue in the last hour"
          description: "Revenue in the last hour is less than $100"

  # ========================================
  # APPLICATION ALERTS
  # ========================================
  - name: application_alerts
    interval: 30s
    rules:
      - alert: HighErrorRate
        expr: rate(gangrun_errors_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          team: engineering
        annotations:
          summary: "High application error rate"
          description: "Error rate is {{ $value }} errors per second (threshold: 0.05)"

      - alert: SlowAPIResponse
        expr: histogram_quantile(0.95, rate(gangrun_http_request_duration_ms_bucket[5m])) > 1000
        for: 10m
        labels:
          severity: warning
          team: engineering
        annotations:
          summary: "API response time degradation"
          description: "95th percentile response time is {{ $value }}ms (threshold: 1000ms)"

      - alert: HighMemoryUsage
        expr: gangrun_nodejs_heap_size_used_bytes / gangrun_nodejs_heap_size_total_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          team: engineering
        annotations:
          summary: "High Node.js heap memory usage"
          description: "Heap memory usage is {{ $value | humanizePercentage }}"

      - alert: ApplicationDown
        expr: up{job="gangrunprinting"} == 0
        for: 1m
        labels:
          severity: critical
          team: engineering
        annotations:
          summary: "GangRun Printing application is down"
          description: "The main application is not responding to health checks"

  # ========================================
  # DATABASE ALERTS
  # ========================================
  - name: database_alerts
    interval: 30s
    rules:
      - alert: DatabaseConnectionPoolExhausted
        expr: gangrun_db_connection_pool{state="waiting"} > 5
        for: 5m
        labels:
          severity: warning
          team: engineering
        annotations:
          summary: "Database connection pool has waiting connections"
          description: "{{ $value }} connections are waiting for database access"

      - alert: SlowDatabaseQueries
        expr: histogram_quantile(0.95, rate(gangrun_db_query_duration_ms_bucket[5m])) > 500
        for: 10m
        labels:
          severity: warning
          team: engineering
        annotations:
          summary: "Database queries are slow"
          description: "95th percentile query time is {{ $value }}ms (threshold: 500ms)"

      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          team: engineering
        annotations:
          summary: "PostgreSQL database is down"
          description: "PostgreSQL is not responding to health checks"

  # ========================================
  # INFRASTRUCTURE ALERTS
  # ========================================
  - name: infrastructure_alerts
    interval: 30s
    rules:
      - alert: HighCPUUsage
        expr: (1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.8
        for: 10m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value | humanizePercentage }}"

      - alert: HighMemoryUsageSystem
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.9
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "High system memory usage"
          description: "Memory usage is {{ $value | humanizePercentage }}"

      - alert: DiskSpaceRunningOut
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.15
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Disk space is running out"
          description: "Only {{ $value | humanizePercentage }} of disk space remaining"

      - alert: HighNetworkTraffic
        expr: rate(node_network_receive_bytes_total[5m]) > 100000000
        for: 5m
        labels:
          severity: info
          team: infrastructure
        annotations:
          summary: "High network traffic detected"
          description: "Network receive traffic is {{ $value | humanize }}B/s"

  # ========================================
  # AUTHENTICATION & SECURITY ALERTS
  # ========================================
  - name: security_alerts
    interval: 30s
    rules:
      - alert: HighAuthFailureRate
        expr: rate(gangrun_auth_attempts_total{success="false"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          team: security
        annotations:
          summary: "High authentication failure rate"
          description: "{{ $value }} failed auth attempts per second"

      - alert: SuspiciousActivity
        expr: rate(gangrun_errors_total{type="security"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
          team: security
        annotations:
          summary: "Security error detected"
          description: "Security-related errors are being logged"

  # ========================================
  # MONITORING SYSTEM ALERTS
  # ========================================
  - name: monitoring_alerts
    interval: 30s
    rules:
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus monitoring system is not operational"

      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Grafana is down"
          description: "Grafana dashboard is not accessible"

      - alert: HighMetricsScrapeFailure
        expr: up == 0
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "Metrics scrape failing for {{ $labels.job }}"
          description: "Prometheus cannot scrape metrics from {{ $labels.instance }}"